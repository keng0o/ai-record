"use client";

import html2canvas from "html2canvas";
import pixelmatch from "pixelmatch";
import { useEffect, useRef, useState } from "react";

interface ScreenshotCaptureProps {
  chatId: string;
  onSaveScreenshot: (chatId: string, dataUrl: string) => void;
  onStopAndProcess: () => void;
  onScreenshotTaken?: () => void;
}

// å®šæ•°ã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ç§»å‹•
const CAPTURE_CONFIG = {
  THRESHOLD: 0.1,
  MIN_DIFF_PERCENTAGE: 0.01,
} as const;

export default function ScreenshotCapture({
  chatId,
  onSaveScreenshot,
  onStopAndProcess,
  onScreenshotTaken,
}: ScreenshotCaptureProps) {
  const [isCapturing, setIsCapturing] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [intervalSec, setIntervalSec] = useState(5);

  const captureIntervalRef = useRef<ReturnType<typeof setInterval> | null>(
    null
  );
  const streamRef = useRef<MediaStream | null>(null);
  const videoRef = useRef<HTMLVideoElement | null>(null);
  const targetRef = useRef<HTMLDivElement | null>(null);

  const [previousImageData, setPreviousImageData] = useState<ImageData | null>(
    null
  );

  // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒã‚¢ãƒ³ãƒã‚¦ãƒ³ãƒˆã•ã‚ŒãŸæ™‚ã«ã¯ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’åœæ­¢
  useEffect(() => {
    return () => {
      stopCapture();
    };
  }, []);

  const startCapture = async () => {
    if (isCapturing) return;

    try {
      const stream = await navigator.mediaDevices.getDisplayMedia();

      if (!videoRef.current) {
        throw new Error("Video element not found");
      }

      streamRef.current = stream;
      videoRef.current.srcObject = stream;
      setIsCapturing(true);
      setIsPaused(false);

      captureIntervalRef.current = setInterval(() => {
        if (!isPaused) {
          takeScreenshot();
        }
      }, intervalSec * 1000);
    } catch (err) {
      console.error("Error starting capture:", err);
      // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
      alert("ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ");
    }
  };

  // åœæ­¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸã¨ãã®å‡¦ç† (ä¾‹: APIå‘¼ã³å‡ºã—ã§ã¾ã¨ã‚ã¦è§£æ)
  const onClickStopButton = async () => {
    stopCapture();
    onStopAndProcess();
  };

  const pauseCapture = () => {
    setIsPaused(true);
  };

  const resumeCapture = () => {
    setIsPaused(false);
  };

  const stopCapture = () => {
    setIsCapturing(false);
    setIsPaused(false);
    if (captureIntervalRef.current) {
      clearInterval(captureIntervalRef.current);
      captureIntervalRef.current = null;
    }
    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => track.stop());
      streamRef.current = null;
    }
  };

  const compareImages = (newImageData: ImageData): boolean => {
    // åˆå›ã®æ’®å½±æ™‚ã¯å¿…ãšä¿å­˜
    if (!previousImageData) {
      console.log("åˆå›ã®æ’®å½±ãªã®ã§ä¿å­˜ã—ã¾ã™");
      return true;
    }

    // ç”»åƒã‚µã‚¤ã‚ºãŒç•°ãªã‚‹å ´åˆã¯å·®åˆ†ã‚ã‚Šã¨ã¿ãªã™
    if (
      previousImageData.width !== newImageData.width ||
      previousImageData.height !== newImageData.height
    ) {
      console.log("ç”»åƒã‚µã‚¤ã‚ºãŒç•°ãªã‚‹ãŸã‚ä¿å­˜ã—ã¾ã™");
      return true;
    }

    const width = newImageData.width;
    const height = newImageData.height;
    const diffOutput = new Uint8Array(width * height * 4); // RGBAç”¨ã®ãƒãƒƒãƒ•ã‚¡

    const numDiffPixels = pixelmatch(
      previousImageData.data,
      newImageData.data,
      diffOutput,
      width,
      height,
      {
        threshold: CAPTURE_CONFIG.THRESHOLD,
        includeAA: true, // ã‚¢ãƒ³ãƒã‚¨ã‚¤ãƒªã‚¢ã‚¹ã‚’å«ã‚ã‚‹
        alpha: 0.1, // ã‚¢ãƒ«ãƒ•ã‚¡å€¤ã®é‡ã¿
        diffColor: [255, 0, 0], // å·®åˆ†ã‚’èµ¤è‰²ã§è¡¨ç¤º
      }
    );

    const totalPixels = width * height;
    const diffPercentage = numDiffPixels / totalPixels;

    console.log(`å·®åˆ†ãƒ”ã‚¯ã‚»ãƒ«æ•°: ${numDiffPixels}`);
    console.log(`ç·ãƒ”ã‚¯ã‚»ãƒ«æ•°: ${totalPixels}`);

    const shouldSave = diffPercentage >= CAPTURE_CONFIG.MIN_DIFF_PERCENTAGE;

    console.log(
      shouldSave ? "å·®åˆ†ãŒååˆ†ã‚ã‚‹ãŸã‚ä¿å­˜ã—ã¾ã™" : "å·®åˆ†ãŒå°ã•ã„ãŸã‚ç ´æ£„ã—ã¾ã™"
    );

    return shouldSave;
  };

  const takeScreenshot = async () => {
    if (!videoRef.current) return;
    const video = videoRef.current;

    // ãƒ“ãƒ‡ã‚ªã®æº–å‚™ãŒã§ãã¦ã„ã‚‹ã‹ç¢ºèª
    if (video.readyState !== video.HAVE_ENOUGH_DATA) {
      console.log("ãƒ“ãƒ‡ã‚ªãƒ‡ãƒ¼ã‚¿ãŒæº–å‚™ã§ãã¦ã„ã¾ã›ã‚“");
      return;
    }

    const canvas = document.createElement("canvas");
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext("2d", { willReadFrequently: true });
    console.log("ğŸš€ ~ takeScreenshot ~ ctx:", ctx);
    if (!ctx) return;

    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    try {
      // æ–°ã—ã„ç”»åƒã®ImageDataã‚’å–å¾—
      const newImageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

      // ç”»åƒã‚’æ¯”è¼ƒ
      const hasSufficientDiff = compareImages(newImageData);

      if (!hasSufficientDiff) {
        console.log("å‰å›ã®ç”»åƒã¨å·®åˆ†ãŒå°ã•ã™ãã¾ã™");
        return;
      }

      // ç¾åœ¨ã®ç”»åƒã‚’ä¿å­˜
      setPreviousImageData(newImageData);

      const dataUrl = canvas.toDataURL("image/png");
      onSaveScreenshot(chatId, dataUrl);
    } catch (error) {
      console.error("ç”»åƒã®æ¯”è¼ƒä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:", error);
    }
  };

  const handleScreenshot = async () => {
    try {
      setIsCapturing(true);
      const canvas = await html2canvas(targetRef.current!);
      const blob = await new Promise<Blob>((resolve) => {
        canvas.toBlob((blob) => resolve(blob!), "image/png");
      });

      const formData = new FormData();
      formData.append("file", blob, "screenshot.png");

      const response = await fetch("/api/uploadImage", {
        method: "POST",
        body: formData,
      });

      const result = await response.json();

      if (!result.success) {
        // ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        alert(result.error);
        return;
      }

      // æˆåŠŸæ™‚ã®å‡¦ç†
      onScreenshotTaken && onScreenshotTaken();
    } catch (error) {
      console.error("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ:", error);
      alert("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ");
    } finally {
      setIsCapturing(false);
    }
  };

  return (
    <div className="p-2 border-b flex items-center space-x-2">
      {/* ã“ã®videoè¦ç´ ã¯ç”»é¢è¡¨ç¤ºã«ã¯éš ã—ã¦ã„ã¾ã™ãŒã€ã‚­ãƒ£ãƒ—ãƒãƒ£ç”¨ã¨ã—ã¦è£ã§åˆ©ç”¨ */}
      <video ref={videoRef} autoPlay style={{ display: "none" }} />
      <label>é–“éš”(ç§’): </label>
      <input
        type="number"
        value={intervalSec}
        onChange={(e) => setIntervalSec(Number(e.target.value))}
        className="w-20 border px-2"
        min={1}
      />

      <div className="flex items-center space-x-4 mb-2">
        <button
          onClick={startCapture}
          disabled={isCapturing}
          className={`px-4 py-2 rounded ${
            isCapturing
              ? "bg-gray-400 cursor-not-allowed"
              : "bg-blue-500 text-white"
          }`}
        >
          é–‹å§‹
        </button>
        {isCapturing && (
          <>
            <button
              onClick={() => setIsPaused(!isPaused)}
              className="px-4 py-2 rounded bg-yellow-500 text-white"
            >
              {isPaused ? "å†é–‹" : "ä¸€æ™‚åœæ­¢"}
            </button>
            <button
              onClick={() => {
                stopCapture();
                onStopAndProcess();
              }}
              className="px-4 py-2 rounded bg-red-500 text-white"
            >
              åœæ­¢
            </button>
          </>
        )}
        <div className="flex items-center">
          <span className="mr-2">é–“éš”:</span>
          <input
            type="number"
            value={intervalSec}
            onChange={(e) => setIntervalSec(Number(e.target.value))}
            className="w-20 px-2 py-1 border rounded"
            min="1"
          />
          <span className="ml-1">ç§’</span>
        </div>
      </div>
    </div>
  );
}
